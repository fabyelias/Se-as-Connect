# SeÃ±as Connect ğŸ¤

**AplicaciÃ³n de comunicaciÃ³n inclusiva en tiempo real entre personas sordomudas y oyentes.**

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Version](https://img.shields.io/badge/version-1.0.0-green.svg)

---

## ğŸ“‹ DescripciÃ³n

SeÃ±as Connect es una aplicaciÃ³n web que permite la comunicaciÃ³n bidireccional entre personas sordomudas y personas oyentes mediante:

1. **Reconocimiento de lengua de seÃ±as** â†’ Detecta gestos con la cÃ¡mara y los convierte en texto y audio
2. **Reconocimiento de voz** â†’ Convierte el habla en texto visible para personas sordas

### Caso de uso principal

Un quiosquero apunta la cÃ¡mara de su celular o computadora hacia una persona sordomuda:
- La persona hace seÃ±as â†’ La app traduce a texto y audio
- El quiosquero habla â†’ La app muestra el texto en pantalla grande

---

## âœ¨ CaracterÃ­sticas

- âœ… DetecciÃ³n de manos en tiempo real con MediaPipe
- âœ… Reconocimiento de gestos y seÃ±as bÃ¡sicas
- âœ… Text-to-Speech (texto a audio) en espaÃ±ol
- âœ… Speech-to-Text (voz a texto) en espaÃ±ol
- âœ… Interfaz accesible con alto contraste
- âœ… TamaÃ±o de texto ajustable
- âœ… Modo pantalla completa
- âœ… Funciona en computadoras y mÃ³viles
- âœ… No requiere instalaciÃ³n (funciona en el navegador)

---

## ğŸš€ InstalaciÃ³n y EjecuciÃ³n

### OpciÃ³n 1: Usando Python (Recomendado)

```bash
# 1. Navegar a la carpeta del proyecto
cd senas-connect

# 2. Ejecutar el servidor
python server.py
```

El navegador se abrirÃ¡ automÃ¡ticamente en `http://localhost:8080`

### OpciÃ³n 2: Usando Node.js

```bash
# 1. Navegar a la carpeta del proyecto
cd senas-connect

# 2. Instalar dependencias
npm install

# 3. Iniciar el servidor
npm start
```

Abrir el navegador en `http://localhost:8080`

### OpciÃ³n 3: Usando Visual Studio Code

1. Instalar la extensiÃ³n **Live Server**
2. Hacer clic derecho en `index.html`
3. Seleccionar "Open with Live Server"

---

## ğŸ’» Requisitos del Sistema

### Navegadores compatibles
- âœ… Google Chrome (recomendado)
- âœ… Microsoft Edge
- âœ… Firefox (soporte parcial para Speech-to-Text)
- âš ï¸ Safari (soporte limitado)

### Hardware
- CÃ¡mara web o cÃ¡mara del dispositivo mÃ³vil
- MicrÃ³fono (para reconocimiento de voz)
- Altavoces (para reproducciÃ³n de audio)

---

## ğŸ“– GuÃ­a de Uso

### Panel Izquierdo: Lengua de SeÃ±as â†’ Texto/Audio

1. PresionÃ¡ **"Iniciar CÃ¡mara"**
2. PermitÃ­ el acceso a la cÃ¡mara cuando el navegador lo solicite
3. HacÃ© seÃ±as frente a la cÃ¡mara
4. El texto reconocido aparecerÃ¡ en pantalla
5. PresionÃ¡ **"Reproducir Audio"** para escuchar el mensaje

### Panel Derecho: Voz â†’ Texto

1. PresionÃ¡ **"Comenzar a Escuchar"**
2. PermitÃ­ el acceso al micrÃ³fono
3. HablÃ¡ claramente
4. El texto aparecerÃ¡ en pantalla grande para que la persona sorda pueda leerlo

### Gestos Reconocidos

| Gesto | Significado |
|-------|-------------|
| ğŸ–ï¸ Mano abierta | Hola |
| ğŸ‘ Pulgar arriba | Bien / De acuerdo |
| ğŸ‘ Pulgar abajo | Mal / No estÃ¡ bien |
| â˜ï¸ SeÃ±alar | Esto |
| âœŒï¸ Dos dedos | 2 |
| ğŸ¤Ÿ Tres dedos | 3 |
| âœ‹ Cuatro dedos | 4 |
| ğŸ–ï¸ Cinco dedos | 5 |
| ğŸ‘Œ OK | OK / Perfecto |
| ğŸ¤™ TelÃ©fono | Llamame |

---

## â™¿ Accesibilidad

La aplicaciÃ³n incluye varias caracterÃ­sticas de accesibilidad:

### Alto Contraste
- PresionÃ¡ el botÃ³n **â—** en la esquina superior derecha
- O usÃ¡ el atajo **Alt + C**

### TamaÃ±o de Texto
- PresionÃ¡ el botÃ³n **A+** para aumentar el tamaÃ±o
- O usÃ¡ el atajo **Alt + F**
- Cicla entre: Normal â†’ Grande â†’ Muy Grande

### Pantalla Completa
- PresionÃ¡ el botÃ³n **â›¶** para modo pantalla completa
- O usÃ¡ **Alt + Enter** o **F11**

### Feedback Visual
- Indicador verde cuando se detectan manos
- AnimaciÃ³n cuando se reconoce un gesto
- VibraciÃ³n en dispositivos mÃ³viles (si estÃ¡ disponible)

---

## ğŸ”§ ConfiguraciÃ³n Avanzada

El archivo `js/config.js` contiene todas las configuraciones ajustables:

```javascript
// Ejemplo: Cambiar el idioma de voz
CONFIG.tts.language = 'es-ES';  // EspaÃ±ol de EspaÃ±a

// Ejemplo: Ajustar sensibilidad de detecciÃ³n
CONFIG.mediapipe.minDetectionConfidence = 0.8;

// Ejemplo: Desactivar auto-reproducciÃ³n de audio
CONFIG.tts.autoSpeak = false;
```

---

## ğŸ› ï¸ Estructura del Proyecto

```
senas-connect/
â”œâ”€â”€ index.html              # PÃ¡gina principal
â”œâ”€â”€ server.py               # Servidor de desarrollo Python
â”œâ”€â”€ package.json            # ConfiguraciÃ³n npm
â”œâ”€â”€ README.md               # Esta documentaciÃ³n
â”‚
â”œâ”€â”€ css/
â”‚   â”œâ”€â”€ styles.css          # Estilos principales
â”‚   â””â”€â”€ accessibility.css   # Estilos de accesibilidad
â”‚
â”œâ”€â”€ js/
â”‚   â”œâ”€â”€ config.js           # ConfiguraciÃ³n global
â”‚   â”œâ”€â”€ sign-dictionary.js  # Diccionario de seÃ±as
â”‚   â”œâ”€â”€ hand-detector.js    # DetecciÃ³n de manos (MediaPipe)
â”‚   â”œâ”€â”€ sign-recognizer.js  # Reconocimiento de gestos
â”‚   â”œâ”€â”€ speech-services.js  # TTS y STT
â”‚   â”œâ”€â”€ accessibility.js    # Funciones de accesibilidad
â”‚   â””â”€â”€ app.js              # AplicaciÃ³n principal
â”‚
â””â”€â”€ backend/                # Backend opcional (Python)
    â”œâ”€â”€ main.py             # API FastAPI
    â””â”€â”€ requirements.txt    # Dependencias Python
```

---

## ğŸ”¬ Backend Avanzado (Opcional)

El backend Python proporciona procesamiento ML mÃ¡s avanzado:

### InstalaciÃ³n

```bash
# 1. Navegar a la carpeta del backend
cd backend

# 2. Crear entorno virtual (recomendado)
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Ejecutar
python main.py
```

El backend estarÃ¡ disponible en `http://localhost:8000`

### DocumentaciÃ³n de la API
Visitar `http://localhost:8000/docs` para ver la documentaciÃ³n interactiva (Swagger).

---

## ğŸ“Š Agregar Nuevas SeÃ±as

### MÃ©todo 1: Agregar gestos simples (solo posiciÃ³n de dedos)

Editar `js/sign-dictionary.js`:

```javascript
// En el objeto SimpleGestures, agregar:
mi_nueva_sena: {
    name: 'Mi SeÃ±a',
    text: 'El texto que se mostrarÃ¡',
    pattern: {
        thumb: true,     // Pulgar extendido
        index: true,     // Ãndice extendido
        middle: false,   // Medio doblado
        ring: false,     // Anular doblado
        pinky: false,    // MeÃ±ique doblado
    },
    minConfidence: 0.85,  // Confianza mÃ­nima
},
```

### MÃ©todo 2: Agregar seÃ±as complejas (con movimiento)

Para seÃ±as que requieren movimiento, se necesita entrenar un modelo de ML.
Ver la secciÃ³n de "Mejoras Futuras" para mÃ¡s informaciÃ³n.

---

## ğŸš§ Limitaciones Conocidas

1. **Diccionario limitado**: El sistema reconoce gestos bÃ¡sicos. Para LSA completa se requiere entrenamiento con datos reales.

2. **IluminaciÃ³n**: Funciona mejor con buena iluminaciÃ³n.

3. **Velocidad de internet**: La primera carga puede ser lenta mientras se descargan los modelos de MediaPipe.

4. **Safari**: El reconocimiento de voz tiene soporte limitado en Safari/iOS.

5. **Movimiento**: Actualmente no se detectan seÃ±as con movimiento, solo posiciÃ³n estÃ¡tica.

---

## ğŸ”® Mejoras Futuras

1. **Entrenamiento con LSA real**
   - Recopilar dataset de Lengua de SeÃ±as Argentina
   - Entrenar modelo de clasificaciÃ³n con TensorFlow

2. **DetecciÃ³n de movimiento**
   - Implementar tracking temporal para detectar seÃ±as dinÃ¡micas

3. **Modo offline**
   - Service Worker para funcionamiento sin internet

4. **MÃºltiples idiomas**
   - Soporte para ASL (American Sign Language)
   - Soporte para otros idiomas de seÃ±as

5. **AplicaciÃ³n mÃ³vil nativa**
   - VersiÃ³n para Android (React Native o Flutter)
   - VersiÃ³n para iOS

6. **IntegraciÃ³n con IA generativa**
   - Uso de modelos de lenguaje para contexto
   - PredicciÃ³n de palabras

---

## ğŸ¤ Contribuir

Las contribuciones son bienvenidas:

1. Fork del repositorio
2. Crear rama de feature (`git checkout -b feature/NuevaCaracteristica`)
3. Commit de cambios (`git commit -m 'Agregar nueva caracterÃ­stica'`)
4. Push a la rama (`git push origin feature/NuevaCaracteristica`)
5. Abrir Pull Request

---

## ğŸ“œ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

---

## ğŸ™ Agradecimientos

- [MediaPipe](https://mediapipe.dev/) por las soluciones de detecciÃ³n de manos
- [Web Speech API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API) para TTS y STT
- La comunidad sorda por inspirar este proyecto

---

## ğŸ“ Contacto

Para reportar bugs, sugerencias o colaboraciones:
- Abrir un Issue en el repositorio
- Contactar al desarrollador

---

**Hecho con â¤ï¸ para una comunicaciÃ³n mÃ¡s inclusiva**
